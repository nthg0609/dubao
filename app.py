import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score
import joblib
import os

# --- Import c√°c model ƒë√∫ng chu·∫©n interface (theo file b·∫°n g·ª≠i) ---
from models.lstm_model import run_lstm_model
from models.tcn_model import run_tcn
from models.transformer_model import run_transformer
from models.hybrid_model import run_hybrid
from models.informer_model import run_informer
from models.autoformer_model import run_autoformer
from models.arima_model import ARIMAModel
# from models.svr_model import run_svr, train_svr_multi_step, predict_svr_multi_step
from models.rf_model import train_rf_multi_step, predict_rf_multi_step
from models.rf_model import run_rf
from models.xgb_model import run_xgb

# ---- CONFIG STREAMLIT ----
st.set_page_config(
    page_title="D·ª± b√°o gi√° c·ªï phi·∫øu",
    page_icon="üìà",
    layout="wide"
)
st.title("üìà D·ª± b√°o gi√° c·ªï phi·∫øu v·ªõi c√°c m√¥ h√¨nh Machine Learning & Deep Learning hi·ªán ƒë·∫°i")

# ---- SIDEBAR: UPLOAD V√Ä CH·ªåN MODEL ----
st.sidebar.header("C·∫•u h√¨nh")
uploaded_file = st.sidebar.file_uploader("Ch·ªçn file d·ªØ li·ªáu", type=['csv'])

# ==== X·ª¨ L√ù D·ªÆ LI·ªÜU ====
if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')
    df = df.sort_values('Date')
    df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'VWAP']].dropna()
    st.subheader("üîé Xem d·ªØ li·ªáu ƒë·∫ßu v√†o")
    st.dataframe(df.head())
    # ==== TH√äM ƒêO·∫†N N√ÄY ====
    unique_dates = df["Date"].dt.strftime("%Y-%m-%d").unique()
    st.sidebar.markdown("### Ch·ªçn kho·∫£ng ng√†y d·ª± b√°o")
    start_date = st.sidebar.selectbox("T·ª´ ng√†y", options=unique_dates, index=0)
    end_date = st.sidebar.selectbox("ƒê·∫øn ng√†y", options=unique_dates, index=len(unique_dates)-1)

    start_date_obj = pd.to_datetime(start_date)
    end_date_obj = pd.to_datetime(end_date)

    # ==== ƒêO·∫†N S·ª¨A 2: KI·ªÇM TRA S·ªê NG√ÄY T·ªêI THI·ªÇU ====
    # C√°c gi√° tr·ªã m·∫∑c ƒë·ªãnh cho look_back v√† pred_steps (l·∫•y ·ªü ƒë√¢y ƒë·ªÉ check)
    look_back = st.sidebar.slider("Window size", 10, 60, 30, key="look_back_check")
    pred_steps = st.sidebar.slider("S·ªë b∆∞·ªõc d·ª± b√°o", 1, 14, 7, key="pred_steps_check")
    min_days = look_back + pred_steps - 1
    num_days = (end_date_obj - start_date_obj).days + 1
    if num_days < min_days:
        st.warning(f"Kho·∫£ng ng√†y b·∫°n ch·ªçn ph·∫£i c√≥ √≠t nh·∫•t {min_days} ng√†y (Window size = {look_back}, S·ªë b∆∞·ªõc d·ª± b√°o = {pred_steps})")
        st.stop()

    # L·ªçc l·∫°i d·ªØ li·ªáu theo ng√†y
    df_filtered = df[(df["Date"] >= start_date_obj) & (df["Date"] <= end_date_obj)]
    st.subheader("üìä Ph√¢n t√≠ch th·ªëng k√™ d·ªØ li·ªáu")
    st.write(df.describe())
    st.write("Missing values:", df.isnull().sum())
    fig, ax = plt.subplots(figsize=(8, 5))
    sns.heatmap(df.corr(), annot=True, cmap='coolwarm', ax=ax)
    st.pyplot(fig)

    # ==== SIDEBAR: CONFIG MODEL ====
    st.sidebar.subheader("C·∫•u h√¨nh d·ª± b√°o")
    model_type = st.sidebar.selectbox(
        "Ch·ªçn m√¥ h√¨nh", [
            "LSTM", "TCN", "Transformer", "Hybrid", "Informer", "Autoformer", "ARIMA", "Random Forest", "XGBoost"
        ]
    )
    forecast_type = st.sidebar.selectbox(
        "Ki·ªÉu d·ª± b√°o", [
            "ƒê∆°n bi·∫øn (Univariate)", "ƒêa bi·∫øn (Multivariate)"
        ]
    )
    look_back = st.sidebar.slider("Window size", 10, 60, 30)
    pred_steps = st.sidebar.slider("S·ªë b∆∞·ªõc d·ª± b√°o", 1, 14, 7)

    # ==== C·∫§U H√åNH RI√äNG T·ª™NG MODEL ====
    if model_type == "LSTM":
        hidden_size = st.sidebar.slider("Hidden size", 32, 256, 64)
        num_layers = st.sidebar.slider("S·ªë l·ªõp LSTM", 1, 4, 2)
        dropout = st.sidebar.slider("Dropout", 0.0, 0.5, 0.2)
    elif model_type == "TCN":
        num_channels = st.sidebar.text_input("S·ªë channel (vd: 64,32,16)", "64,32,16")
        num_channels = [int(i) for i in num_channels.split(',')]
        kernel_size = st.sidebar.slider("Kernel size", 2, 8, 3)
        dropout = st.sidebar.slider("Dropout", 0.0, 0.5, 0.2)
    elif model_type == "Transformer":
        d_model = st.sidebar.slider("d_model", 32, 256, 64)
        nhead = st.sidebar.slider("S·ªë head", 1, 16, 8)
        num_layers = st.sidebar.slider("S·ªë l·ªõp", 1, 6, 2)
        dim_feedforward = st.sidebar.slider("Feedforward dim", 32, 512, 256)
        dropout = st.sidebar.slider("Dropout", 0.0, 0.5, 0.1)
    elif model_type == "Hybrid":
        hidden_size = st.sidebar.slider("Hidden size", 32, 256, 64)
        num_layers = st.sidebar.slider("S·ªë l·ªõp", 1, 4, 2)
        dropout = st.sidebar.slider("Dropout", 0.0, 0.5, 0.2)
    elif model_type == "Informer":
        d_model = st.sidebar.slider("d_model", 32, 256, 64)
        n_layers = st.sidebar.slider("S·ªë l·ªõp", 1, 6, 2)
        d_ff = st.sidebar.slider("d_ff", 64, 512, 256)
        dropout = st.sidebar.slider("Dropout", 0.0, 0.5, 0.1)
    elif model_type == "Autoformer":
        d_model = st.sidebar.slider("d_model", 32, 256, 64)
        n_layers = st.sidebar.slider("S·ªë l·ªõp", 1, 6, 2)
        d_ff = st.sidebar.slider("d_ff", 64, 512, 256)
        dropout = st.sidebar.slider("Dropout", 0.0, 0.5, 0.1)
    elif model_type == "ARIMA":
        p = st.sidebar.slider("p", 0, 5, 1)
        d = st.sidebar.slider("d", 0, 2, 1)
        q = st.sidebar.slider("q", 0, 5, 1)
    elif model_type == "Random Forest":
        n_estimators = st.sidebar.slider("n_estimators", 50, 500, 100)
        max_depth = st.sidebar.slider("max_depth", 3, 30, 10)
        min_samples_split = st.sidebar.slider("min_samples_split", 2, 10, 5)
    # elif model_type == "SVR":
    #     kernel = st.sidebar.selectbox("Kernel", ["rbf", "linear", "poly", "sigmoid"])
    #     C = st.sidebar.slider("C", 0.1, 10.0, 1.0)
    #     epsilon = st.sidebar.slider("epsilon", 0.01, 0.5, 0.1)

    elif model_type == "XGBoost":
        n_estimators = st.sidebar.slider("n_estimators", 50, 500, 100)
        max_depth = st.sidebar.slider("max_depth", 2, 16, 6)
        learning_rate = st.sidebar.slider("learning_rate", 0.01, 0.5, 0.1)
        subsample = st.sidebar.slider("subsample", 0.5, 1.0, 0.8)

    # ==== PH·∫¶N CH·∫†Y MODEL THEO L·ª∞A CH·ªåN ====
    st.sidebar.markdown("---")
    st.sidebar.write("### Hu·∫•n luy·ªán m√¥ h√¨nh")
    if st.sidebar.button("B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán v√† d·ª± b√°o"):
        with st.spinner("ƒêang x·ª≠ l√Ω v√† hu·∫•n luy·ªán m√¥ h√¨nh..."):
            # === Univariate/multivariate config ===
            univariate = (forecast_type == "ƒê∆°n bi·∫øn (Univariate)")
            features = ['Open','High','Low','Close','Volume','VWAP']
            res_df, metrics = None, None  # Kh·ªüi t·∫°o gi√° tr·ªã m·∫∑c ƒë·ªãnh
            if model_type == "LSTM":
                _, res_df, metrics = run_lstm_model(
                    df=df_filtered, univariate=univariate, look_back=look_back, pred_steps=pred_steps,
                    hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, plot=False
                )
            elif model_type == "TCN":
                _, res_df, metrics = run_tcn(
                    df=df_filtered, univariate=univariate, look_back=look_back, pred_steps=pred_steps,
                    num_channels=num_channels, kernel_size=kernel_size, dropout=dropout,
                    batch_size=32, epochs=50, lr=0.001
                )
            elif model_type == "Transformer":
                _, res_df, metrics = run_transformer(
                    df=df_filtered, univariate=univariate, look_back=look_back, pred_steps=pred_steps,
                    d_model=d_model, nhead=nhead, num_layers=num_layers,
                    dim_feedforward=dim_feedforward, dropout=dropout,
                    batch_size=32, epochs=50, lr=0.001
                )
            elif model_type == "Hybrid":
                _, res_df, metrics = run_hybrid(
                    df=df_filtered, univariate=univariate, look_back=look_back, pred_steps=pred_steps,
                    hidden_size=hidden_size, num_layers=num_layers, dropout=dropout,
                    batch_size=32, epochs=50, lr=0.001
                )
            elif model_type == "Informer":
                _, res_df, metrics = run_informer(
                    df=df_filtered, univariate=univariate, look_back=look_back, pred_steps=pred_steps,
                    d_model=d_model, n_layers=n_layers, d_ff=d_ff, dropout=dropout,
                    batch_size=32, epochs=50, lr=0.001
                )
            elif model_type == "Autoformer":
                _, res_df, metrics = run_autoformer(
                    df=df_filtered, univariate=univariate, look_back=look_back, pred_steps=pred_steps,
                    d_model=d_model, n_layers=n_layers, d_ff=d_ff, dropout=dropout,
                    batch_size=32, epochs=50, lr=0.001
                )
            elif model_type == "ARIMA":
                arima = ARIMAModel(p=p, d=d, q=q, window_size=look_back)
                arima_result = arima.run(
                    df=df_filtered, univariate=univariate, window_size=look_back,
                    pred_steps=pred_steps, features=features
                )
                res_df = arima_result["res_df"]
                metrics = arima_result["metrics"]
                # Show b·∫£ng th·ªëng k√™, heatmap, histogram n·∫øu mu·ªën:
                st.subheader("Th·ªëng k√™ m√¥ t·∫£ d·ªØ li·ªáu")
                st.dataframe(arima_result["desc"])
                st.write("Missing values:", arima_result["missing"])
                st.pyplot(arima_result["fig_corr"])
                for fig in arima_result["hist_figs"]:
                    st.pyplot(fig)
                for fig in arima_result["figs"]:
                    st.pyplot(fig)
                st.write("Baseline RMSE (Naive):", arima_result["baseline"])
            # elif model_type == "SVR":
            # #     _, res_df, metrics = run_svr(
            # #         df=df, look_back=look_back, pred_steps=pred_steps
            #     )
            elif model_type == "Random Forest":
                _, res_df, metrics = run_rf(
                    df=df_filtered,
                    look_back=look_back,
                    pred_steps=pred_steps,
                    n_estimators=n_estimators,
                    max_depth=max_depth,
                    min_samples_split=min_samples_split
                )
            
            elif model_type == "XGBoost":
                _, res_df, metrics = run_xgb(
                    df=df_filtered,
                    univariate=univariate,
                    look_back=look_back,
                    pred_steps=pred_steps,
                    n_estimators=100,
                    max_depth=6,
                    learning_rate=0.1,
                    subsample=0.8
                )

            st.success("‚úÖ Hu·∫•n luy·ªán v√† d·ª± b√°o ho√†n t·∫•t.")
            if metrics is not None:
                st.subheader("=== K·∫æT QU·∫¢ ƒê√ÅNH GI√Å MULTI-STEP ===")
                for i, (rmse, mae, mape, r2) in enumerate(metrics):
                    st.write(
                        f"B∆∞·ªõc t+{i+1}: "
                        f"RMSE={rmse:.2f} | "
                        f"MAE={mae:.2f} | "
                        f"MAPE={mape:.2%} | "
                        f"R2={r2:.4f}"
                    )
            # ==== ƒêO·∫†N S·ª¨A 3: HI·ªÇN TH·ªä TO√ÄN B·ªò K·∫æT QU·∫¢ V√Ä BI·ªÇU ƒê·ªí ====
            if res_df is not None:
                # Chuy·ªÉn 'Ng√†y' sang datetime n·∫øu c·∫ßn
                if not np.issubdtype(res_df['Ng√†y'].dtype, np.datetime64):
                    res_df['Ng√†y'] = pd.to_datetime(res_df['Ng√†y'])
                # L·ªçc ƒë√∫ng kho·∫£ng ng√†y ƒë√£ ch·ªçn (d√π model ƒë√£ d·ª± b√°o ƒë√∫ng kho·∫£ng n√†y)
                mask = (res_df['Ng√†y'] >= start_date_obj) & (res_df['Ng√†y'] <= end_date_obj)
                show_df = res_df[mask] if mask.any() else res_df

                st.markdown("#### == B·∫£ng k·∫øt qu·∫£ d·ª± b√°o:")
                st.dataframe(show_df)

                # Bi·ªÉu ƒë·ªì th·ª±c t·∫ø & d·ª± b√°o
                st.markdown("#### == Bi·ªÉu ƒë·ªì gi√° th·ª±c t·∫ø v√† gi√° d·ª± b√°o:")
                fig, ax = plt.subplots(figsize=(12,5))
                ax.plot(show_df['Ng√†y'], show_df['Gi√° th·ª±c t·∫ø'], label="Gi√° th·ª±c t·∫ø", marker='o')
                ax.plot(show_df['Ng√†y'], show_df['Gi√° d·ª± b√°o'], label="Gi√° d·ª± b√°o", marker='o')
                ax.set_xlabel("Ng√†y")
                ax.set_ylabel("Gi√°")
                ax.legend()
                ax.grid(True, alpha=0.3)
                plt.xticks(rotation=45)
                st.pyplot(fig)

else:
    st.info("Vui l√≤ng t·∫£i l√™n file d·ªØ li·ªáu .csv ƒë·ªÉ b·∫Øt ƒë·∫ßu.")